{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment#2-SentimentAnalysis.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ZRhvaZZlS1VE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Dataset credits and copyrights:**\n",
        "\n",
        "InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
        "  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
        "  \n",
        "  title     = {Learning Word Vectors for Sentiment Analysis},\n",
        "  \n",
        "  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
        "  \n",
        "  month     = {June},\n",
        "  \n",
        "  year      = {2011},\n",
        "  \n",
        "  address   = {Portland, Oregon, USA},\n",
        "  \n",
        "  publisher = {Association for Computational Linguistics},\n",
        "  \n",
        "  pages     = {142--150},\n",
        "  \n",
        "  url       = {http://www.aclweb.org/anthology/P11-1015}\n",
        "}\n",
        "\n",
        "\n",
        "References\n",
        "\n",
        "Potts, Christopher. 2011. On the negativity of negation. In Nan Li and\n",
        "David Lutz, eds., Proceedings of Semantics and Linguistic Theory 20,\n",
        "636-659.\n"
      ]
    },
    {
      "metadata": {
        "id": "zmAm1ddciU2q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.a.1. Downloading dataset,extracting compressed files and moving into the folder containg data"
      ]
    },
    {
      "metadata": {
        "id": "CRRDBMtKiVQa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!rm -rf datalab\n",
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!ls\n",
        "!uncompress aclImdb_v1.tar.gz\n",
        "!tar -xvf aclImdb_v1.tar\n",
        "!rm aclImdb_v1.tar\n",
        "!ls\n",
        "!pip install stop-words\n",
        "import nltk\n",
        "nltk.download('popular')\n",
        "!pip install -U gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gNl228xlRzFY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "testing GPU:"
      ]
    },
    {
      "metadata": {
        "id": "HtgzX0RMeYJx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# check whether we connected to GPU or not\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BdMC4sjjR2dI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "directories tree:"
      ]
    },
    {
      "metadata": {
        "id": "zzKG8S_ZB2b2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls aclImdb\n",
        "!ls aclImdb/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rhUtqFlm5WZ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **Reading files containing reviews**"
      ]
    },
    {
      "metadata": {
        "id": "fVfKVfb4R6nu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "getting text files from folders:"
      ]
    },
    {
      "metadata": {
        "id": "ZKBSMyaZ0Ih8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "'''\n",
        "function to read all text file names in a given folder\n",
        "@param  path: given in this form '/path/'\n",
        "'''\n",
        "def txt_file_names_list(path):\n",
        "    txt_files=glob.glob('.'+path+'*.txt')\n",
        "    return txt_files\n",
        "  \n",
        "#testing that function actually works\n",
        "text_files=txt_file_names_list('/aclImdb/train/pos/')\n",
        "print(len(text_files))\n",
        "print(text_files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UBsU7_Mq3TbY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#made lists of names of files containing reviews\n",
        "#tested\n",
        "pos_train_txt_names = txt_file_names_list('/aclImdb/train/pos/')\n",
        "neg_train_txt_names = txt_file_names_list('/aclImdb/train/neg/')\n",
        "pos_test_txt_names = txt_file_names_list('/aclImdb/test/pos/')\n",
        "neg_test_txt_names = txt_file_names_list('/aclImdb/test/neg/')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cRmpm1FCSDJ6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "reading the files to get the reviews' text:"
      ]
    },
    {
      "metadata": {
        "id": "jrosLxnP53sC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Function\n",
        "Given an array of strings of paths(names) of files to be read \n",
        "reads each file and saves all text in a string list\n",
        "\n",
        "@param text_file_names     list of text file names and paths to them\n",
        "@return text_files         list of contents of given text files\n",
        "'''\n",
        "#tested and it works\n",
        "def capture_text_from_files(text_file_paths,number_of_files):\n",
        "  text_files=[]\n",
        "  for fileNo in range(len(text_file_paths)):\n",
        "      f = open(text_file_paths[fileNo], 'r')\n",
        "      lines = f.readlines()\n",
        "      text=\"\"\n",
        "      f.close()\n",
        "      for lineNo in range(len(lines)):\n",
        "        text+=\" \"+lines[lineNo]\n",
        "      text_files.append(text)\n",
        "  return text_files\n",
        "  \n",
        "#testing \n",
        "pos_reviews_train=capture_text_from_files(pos_train_txt_names,len(pos_train_txt_names) )\n",
        "print(len(pos_reviews_train))\n",
        "print(pos_train_txt_names[0])\n",
        "print(pos_reviews_train[1])\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "llQC_RRtkY5w",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#getting reviews text into lists to preprocess :\n",
        "pos_reviews_train_list=capture_text_from_files(pos_train_txt_names,len(pos_train_txt_names) )\n",
        "neg_reviews_train_list=capture_text_from_files(neg_train_txt_names,len(neg_train_txt_names) )\n",
        "pos_reviews_test_list=capture_text_from_files(pos_test_txt_names,len(pos_test_txt_names) )\n",
        "neg_reviews_test_list=capture_text_from_files(neg_test_txt_names,len(pos_train_txt_names) )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hlOY9_015jgq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Text Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "JFaXMKB9EYxk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "removing html tags"
      ]
    },
    {
      "metadata": {
        "id": "8iq6RopT8Ope",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#removing html tags from reviews not to confuse classifiers\n",
        "\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "'''\n",
        "Function to clear all html tags from all text in a list of strings\n",
        "\n",
        "@param text_list : list of strings targeted to clean\n",
        "'''\n",
        "def clean_html_from_list(text_list):\n",
        "\n",
        "  for i in range(len(text_list)):\n",
        "    text_list[i]=BeautifulSoup(text_list[i],\"html5lib\").get_text()\n",
        "    \n",
        "  return text_list\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "enhesunHDn5I",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#using the function on data\n",
        "clean_html_from_list(pos_reviews_train_list)\n",
        "clean_html_from_list(neg_reviews_train_list)\n",
        "clean_html_from_list(pos_reviews_test_list)\n",
        "clean_html_from_list(neg_reviews_test_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sYa3CN13EcZY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### spell checker : (still no good ones in libraries and will use a naive one or implement our own but not necessary )\n",
        "didn't do it to prevent computing overload by hunch it won't improve accuracy by much"
      ]
    },
    {
      "metadata": {
        "id": "yzvfpZ7oEhM6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "#TODO\n",
        "!pip install -U textblob\n",
        "!pip install -U autocorrect\n",
        "from textblob import TextBlob\n",
        "from autocorrect import spell\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BmsvbZkOIWGe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "blob = TextBlob('tihs assignmt si on itss tim excpt fr midtrms')\n",
        "print(\"blob's:\")\n",
        "print(blob.correct())\n",
        "\n",
        "x='tihs assignmt si on itss tim excpt fr midtrms'\n",
        "print(\"autocorrect:\")\n",
        "print(spell(x))\n",
        "\n",
        "#blob better and faster\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h5MmJzYLSdPw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "tokenization:"
      ]
    },
    {
      "metadata": {
        "id": "e8hSvGe41uNg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "def tokenize_list(list_words):\n",
        "  tokens=[]\n",
        "  for review in list_words:\n",
        "    tokens.append(word_tokenize(review))\n",
        "  return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M1pJtrWU2Ah8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "pos_reviews_train_list=tokenize_list(pos_reviews_train_list)\n",
        "neg_reviews_train_list=tokenize_list(neg_reviews_train_list)\n",
        "pos_reviews_test_list=tokenize_list(pos_reviews_test_list)\n",
        "neg_reviews_test_list=tokenize_list(neg_reviews_test_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jNFhRlSdblAn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "pos_train_tokens=pos_reviews_train_list\n",
        "neg_train_tokens=neg_reviews_train_list\n",
        "pos_test_tokens=pos_reviews_test_list\n",
        "neg_test_tokens=neg_reviews_test_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tq5q4fFibk8C",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fMCqWhPWMWsM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## stop words removal (is,are,the,this ....etc) :"
      ]
    },
    {
      "metadata": {
        "id": "5YSOYKj0DGQm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "removing any stop words (written in capital or small letters) and removing punctuations"
      ]
    },
    {
      "metadata": {
        "id": "xPy9rnkr1XD3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from stop_words import get_stop_words\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from functools import reduce\n",
        "import operator\n",
        "\n",
        "\n",
        "stop_words = list(get_stop_words('en')) \n",
        "\n",
        "def remove_stopwords(review):\n",
        "  filtered_words=[]\n",
        "  for tokens in review:\n",
        "    filtered_word=[]\n",
        "    filtered_word = [word for word in tokens if word.lower() not in stop_words]\n",
        "    filtered_words.append(filtered_word)\n",
        "    \n",
        "  return(filtered_words)\n",
        "def remove_punctuations(review):\n",
        "  filtered_words=[]\n",
        "  filtered=[]\n",
        "  for tokens in review:\n",
        "    filtered_word=[]\n",
        "    for token in tokens:\n",
        "        if (token.isalpha()== False):\n",
        "          filtered_word.append(token)\n",
        "    filtered_words=[x.lower() for x in tokens if x not in  filtered_word]\n",
        "    filtered.append(filtered_words)\n",
        "          \n",
        "    \n",
        "  return(filtered)\n",
        "\n",
        "x=remove_stopwords([['the','love',';','.','an','is','hi','is','the','big','are','have','they','efvfdv','I','There','am','i','IS','They'],['big','task']])\n",
        "print(x)\n",
        "X=remove_punctuations(x)\n",
        "print(X)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DT9oyL86bWGp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "pos_train_tokens=remove_stopwords(pos_reviews_train_list)\n",
        "pos_train_tokens=remove_punctuations(pos_train_tokens)\n",
        "print(pos_train_tokens[0])\n",
        "neg_train_tokens=remove_stopwords(neg_reviews_train_list)\n",
        "neg_train_tokens=remove_punctuations(neg_train_tokens)\n",
        "\n",
        "pos_test_tokens=remove_stopwords(pos_reviews_test_list)\n",
        "pos_test_tokens=remove_punctuations(pos_test_tokens)\n",
        "\n",
        "neg_test_tokens=remove_stopwords(neg_reviews_test_list)\n",
        "neg_test_tokens=remove_punctuations(neg_test_tokens)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dJaDGMaSeMs0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Lemmatization**\n",
        "\n",
        "better than stemming"
      ]
    },
    {
      "metadata": {
        "id": "-dsscCxY1eGm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "      \n",
        "\n",
        "\n",
        "def lemmatize_list(list_of_lists_of_tokens):\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  new_list=[]\n",
        "  for review in list_of_lists_of_tokens:\n",
        "    new_review=[]\n",
        "    for token in review:\n",
        "      \n",
        "      if(token not in [\"movie\",\"film\",\"films\",\"movies\",\"will\",\"can\"]):\n",
        "        new_token=x=lemmatizer.lemmatize(token, get_wordnet_pos(nltk.pos_tag([token])[0][1]))\n",
        "        new_review.append(new_token)\n",
        "        \n",
        "    new_list.append(new_review)\n",
        "  return new_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zbNoK4DX6kiu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(pos_train_tokens[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MWQFcfnIeWGy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "pos_train_tokens=lemmatize_list(pos_train_tokens)\n",
        "print(\"lemmatizing 1st\")\n",
        "neg_train_tokens=lemmatize_list(neg_train_tokens)\n",
        "print(\"lemmatizing 2nd\")\n",
        "pos_test_tokens=lemmatize_list(pos_test_tokens)\n",
        "print(\"lemmatizing 3rd\")\n",
        "neg_test_tokens=lemmatize_list(neg_test_tokens)\n",
        "print(\"lemmatizing 4th\")\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8km6pq6lb3nx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk, tree2conlltags\n",
        "nltk.download('popular')\n",
        "# names and locations removing routine\n",
        "# still needs further improvements\n",
        "def remove_name_loc(text):\n",
        "    one=[]\n",
        "    filter=[]\n",
        "    for tokens in text:\n",
        "\n",
        "      ne_tag = tree2conlltags(ne_chunk(pos_tag(tokens)))\n",
        "\n",
        "      i=0\n",
        "      for token in tokens:\n",
        "\n",
        "        if str(ne_tag[i][2])== 'B-PERSON':\n",
        "          pass\n",
        "        elif str(ne_tag[i][2])== 'B-GPE':\n",
        "          pass\n",
        "        elif str(ne_tag[i][2])== 'B-ORGANIZATION':\n",
        "          pass\n",
        "        else:\n",
        "          one.append(token)\n",
        "        i+=1\n",
        "\n",
        "      filter+=[one[:]]\n",
        "      del one[:]\n",
        "    return filter\n",
        " '''   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s9XZCLAKb7ry",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "pos_train_tokens=remove_name_loc(pos_train_tokens)\n",
        "neg_train_tokens=remove_name_loc(neg_train_tokens)\n",
        "pos_test_tokens=remove_name_loc(pos_test_tokens)\n",
        "neg_test_tokens=remove_name_loc(neg_test_tokens)\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d8fkK_JOl0d8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# ZYAD STARTED HERE\n",
        "'''\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk, tree2conlltags\n",
        " \n",
        "sentence = \"Mark and Kareem are working at Canada.\"\n",
        " \n",
        "ne_tree = ne_chunk(pos_tag(word_tokenize(sentence)))\n",
        " \n",
        "iob_tagged = tree2conlltags(ne_tree)\n",
        "print(iob_tagged)\n",
        "\n",
        "# names and locations removing routine\n",
        "# still needs further improvements\n",
        "def remove_name_loc(text):\n",
        "    filtered_words=[]\n",
        "    for tokens in text:\n",
        "      ne_tag = tree2conlltags(ne_chunk(pos_tag(tokens)))\n",
        "      i=0\n",
        "      for token in tokens:\n",
        "        print(token,ne_tag[i][2])\n",
        "        if str(ne_tag[i][2])== 'B-PERSON':\n",
        "          pass\n",
        "        elif str(ne_tag[i][2])== 'B-GPE':\n",
        "          pass\n",
        "        else:\n",
        "          filtered_words.append(token)\n",
        "        i+=1\n",
        "    print(filtered_words)\n",
        "\n",
        "remove_name_loc([['Canada','Adams','nice'],['yes']])'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hQbIbT7JrqyW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "stemming worked badly so removed it this stemmer is better than porter stemmer yet it reduces accuracy and without it the classifying accuracy is better even without lemmatization"
      ]
    },
    {
      "metadata": {
        "id": "700DdaoI0UeW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "def stem_list(list_of_lists_of_tokens):\n",
        "  new_list=[]\n",
        "  for review in list_of_lists_of_tokens:\n",
        "    new_review=[]\n",
        "    for token in review:\n",
        "      if(token not in [\"movie\",\"film\",\"films\",\"movies\",\"will\"]):\n",
        "        new_token=stemmer.stem(token)\n",
        "        new_review.append(new_token)\n",
        "    new_list.append(new_review)\n",
        "  return new_list\n",
        "\n",
        "trial=[ [\"list\",\"word\",\"playing\",\"movie\"],[\"film\",\"production\"],[\"tokenize\",\"stem\"]]\n",
        "trial=stem_list(trial)\n",
        "print(trial)\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sCLJlnX0wpU8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "#Kareem's temporary stemming\n",
        "pos_trian_tokens=stem_list(pos_train_tokens)\n",
        "print(\"stemmed 1st\")\n",
        "neg_train_tokens=stem_list(neg_train_tokens)\n",
        "print(\"stemmed 2nd\")\n",
        "pos_test_tokens=stem_list(pos_test_tokens)\n",
        "print(\"stemmed 3rd\")\n",
        "neg_test_tokens=stem_list(neg_test_tokens)\n",
        "print(\"4th\")\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QiM0-Xm0Dqtw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mahinour's trial for ** Inverse Document Frequency (TF – IDF)** - Done , only def in a function remains\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "80axlXtZH_Uj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#trial is reviews of combined tokens returned from tokenized form\n",
        "trial=[]\n",
        "for j in range (len(pos_train_tokens)):\n",
        "  trial1=\"\"\n",
        "  for i in range(len(pos_train_tokens[j])):\n",
        "    trial1+=pos_train_tokens[j][i]+' '\n",
        "  trial.append(trial1)\n",
        "  \n",
        "trial2=[]\n",
        "for j in range (len(neg_train_tokens)):\n",
        "  trial1=\"\"\n",
        "  for i in range(len(neg_train_tokens[j])):\n",
        "    trial1+=neg_train_tokens[j][i]+' '\n",
        "  trial2.append(trial1)\n",
        "  \n",
        "  \n",
        "trial3=[]\n",
        "for j in range (len(neg_test_tokens)):\n",
        "  trial1=\"\"\n",
        "  for i in range(len(neg_test_tokens[j])):\n",
        "    trial1+=neg_test_tokens[j][i]+' '\n",
        "  trial3.append(trial1)\n",
        "  \n",
        "trial4=[]\n",
        "for j in range (len(pos_test_tokens)):\n",
        "  trial1=\"\"\n",
        "  for i in range(len(pos_test_tokens[j])):\n",
        "    trial1+=pos_test_tokens[j][i]+' '\n",
        "  trial4.append(trial1)  \n",
        "\n",
        "print(\"done\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E_FusLUVvl8s",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''q=[]\n",
        "q.extend(neg_test_tokens)\n",
        "q.extend(pos_test_tokens)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gkL9dEHxGwno",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#train data is list of positive and negative reviews full after preprocessing\n",
        "train_data=[]\n",
        "test_data=[]\n",
        "train_data.extend(trial)\n",
        "train_data.extend(trial2)\n",
        "test_data.extend(trial3)\n",
        "test_data.extend(trial4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Goc_B01ZO9ka",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Doc2Vec"
      ]
    },
    {
      "metadata": {
        "id": "b9cVhNaLPFO-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "!pip install -U gensim\n",
        "from gensim.models import Doc2Vec\n",
        "\n",
        "from gensim.models import doc2vec\n",
        "from collections import namedtuple\n",
        "from collections import OrderedDict\n",
        "import multiprocessing\n",
        "\n",
        "cores = multiprocessing.cpu_count()\n",
        "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
        "\n",
        "# Transform data (you can add more data preprocessing steps) \n",
        "\n",
        "docs = []\n",
        "analyzedDocument = namedtuple('AnalyzedDocument', 'words tags')\n",
        "for i, text in enumerate(train_data):\n",
        "    words = text.lower().split()\n",
        "    tags = [i]\n",
        "    docs.append(analyzedDocument(words, tags))\n",
        "    \n",
        "    \n",
        "model = doc2vec.Doc2Vec(docs , dm_concat=1, vector_size = 100, window = 300, negative=5, hs=0, min_count = 2, workers = cores)\n",
        "\n",
        "print(docs)\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MX81HEUhea9-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MAXIMUM ACCURACY ATTAINED TIL NOW FOR DOC2VEC IS 73% USING LOG. REGRESSION CLASSIFIER :S"
      ]
    },
    {
      "metadata": {
        "id": "20IcRxqljFDE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "from gensim.models import doc2vec\n",
        "from collections import namedtuple\n",
        "import random\n",
        "\n",
        "# Transform data (you can add more data preprocessing steps) \n",
        "assert doc2vec.FAST_VERSION >-1\n",
        "docs = []\n",
        "analyzedDocument = namedtuple('AnalyzedDocument', 'words tags')\n",
        "for i, text in enumerate(train_data):\n",
        "    words = text.lower().split()\n",
        "    tags = [i]\n",
        "    docs.append(analyzedDocument(words, tags))\n",
        "\n",
        "# Train model (set min_count = 1, if you want the model to work with the provided example data set)\n",
        "\n",
        "#model = doc2vec.Doc2Vec(docs, vector_size = 100, window = 20, alpha=0.025, min_alpha=0.025, min_count = 1, workers = 8)\n",
        "model= doc2vec.Doc2Vec(docs,min_count=1, window=10, size=100, sample=1e-4, negative=5, workers=7)\n",
        "for epoch in range(15):\n",
        "    random.shuffle(docs)\n",
        "    model.train(docs, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "    #model.alpha -= 0.002 # decrease the learning rate\n",
        "    #model.min_alpha = model.alpha # fix the learning rate, no deca\n",
        "    #model.train(docs)\n",
        "    '''\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dfXK79mnoFnF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#model.most_similar('comedy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wnsDxa4xa7VK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# http://linanqiu.github.io/2015/10/07/word2vec-sentiment/\n",
        "# https://github.com/linanqiu/word2vec-sentiments/blob/master/word2vec-sentiment.ipynb\n",
        "# https://medium.com/@mishra.thedeepak/doc2vec-in-a-simple-way-fa80bfe81104\n",
        "\n",
        "# <<zyad>> you may open links for illustration about the edits i \"tried\" to make\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dy1lFaVA4jf3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "# ZYAD STARTED HERE\n",
        "\n",
        "# not sure whether this step is valid or not:\n",
        "# i'm trying to generate test reviews vectors by inference using our training model\n",
        "# not sure about the concept but it seems that inferring process is like finding similarity of certain test vector against the training model\n",
        "!pip install -U numpy\n",
        "import numpy as np\n",
        "\n",
        "train_vectors= np.zeros((25000, 100))\n",
        "test_vectors= np.zeros((25000, 100))\n",
        "for i in range(25000):\n",
        "  label = 'test_%s' %i\n",
        "  train_vectors[i]=model[i]\n",
        "  test_vectors[i]= model.infer_vector(word_tokenize(test_data[i]))\n",
        "  '''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9FTUPkCtQyv0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tf-IDF and count vectorizer"
      ]
    },
    {
      "metadata": {
        "id": "8N6Fi5uqG3Hm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "##count #commented to avoid confusion regarding \"test_vectors\" & \"train_vectors\" of mine\n",
        "'''\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
        "train_vectors = vectorizer.fit_transform(train_data)\n",
        "test_vectors = vectorizer.transform(test_data)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O4RkCXoIXoTe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "## tf-IDf #commented to avoid confusion regarding \"test_vectors\" & \"train_vectors\" of mine\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import itertools\n",
        "obj = TfidfVectorizer(ngram_range=(1,2),stop_words='english')\n",
        "train_vectors = obj.fit_transform(train_data)\n",
        "test_vectors = obj.transform(test_data)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DDwGD3jchALx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_label_pos = [0] * 12500\n",
        "train_label_neg = [1] * 12500\n",
        "test_label_pos = [0] * 12500\n",
        "test_label_neg = [1] * 12500\n",
        "train_labels=[]\n",
        "test_labels=[]\n",
        "train_labels.extend(train_label_pos)\n",
        "train_labels.extend(train_label_neg)\n",
        "test_labels.extend(train_label_neg)\n",
        "test_labels.extend(train_label_pos)\n",
        "#print(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dQnFzREKHT9q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "train_vectors10=train_vectors[11250:13750]\n",
        "train_labels10=train_labels[0:1250]\n",
        "train_labels10.extend(train_labels[-1250:])\n",
        "train_vectors90=train_vectors[1250:-1250]\n",
        "train_labels90=train_labels[1250:-1250]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Agmp6C6fVoAv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(train_vectors10.shape)\n",
        "print(len(train_labels10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cfQhHbB1qply",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Tuning**"
      ]
    },
    {
      "metadata": {
        "id": "1pW5R1SEqti-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "we take 10% of data to extract best parameters for each classifier\n",
        "the function grid_search_wrapper returns the classifier loaded with best parameters that give best results\n",
        "\n",
        "and then fit data (90%) using this classifier"
      ]
    },
    {
      "metadata": {
        "id": "pBAR4fukM5n5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "function takes precision score type like accuracy,precision,recall ...etc and \n",
        "returns classifier with best parameters \n",
        "the function has other parameters like clf , train vectors and labels ...etc\n",
        "but they are either hard coded inside or use global variables that change on \n",
        "each classifier cell so it is not generic and cannot be used outside this notebook\n",
        "\n",
        "'''\n",
        "\n",
        "def grid_search_wrapper(refit_score='precision_score'):\n",
        "    \"\"\"\n",
        "    fits a GridSearchCV classifier using refit_score for optimization\n",
        "    prints classifier performance metrics\n",
        "    \"\"\"\n",
        "    \n",
        "    skf = StratifiedKFold(n_splits=10)\n",
        "    '''\n",
        "    GridSearchCV \n",
        "    clf is a global variable outside function  and set before calling it \n",
        "    \n",
        "    param_grid is the parameters values possible also global variables \n",
        "    \n",
        "    scorers always is the accuracy score here\n",
        "    \n",
        "    \n",
        "    '''\n",
        "    grid_search = GridSearchCV(clf, param_grid, scoring=scorers, refit=refit_score,\n",
        "                           cv=skf, return_train_score=True)\n",
        "    grid_search.fit(train_vectors10,train_labels10)\n",
        "    print(\"fit completed\")\n",
        "    print('Best params for {}'.format(refit_score))\n",
        "    print(grid_search.best_params_)\n",
        "    print(\"best params completed\")\n",
        "    print(grid_search.best_estimator_)\n",
        "    print(\"best params completed\")\n",
        "    \n",
        "    return grid_search.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5lXFss-zIR6R",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "##logistic Regression\n",
        "from sklearn import linear_model, datasets\n",
        "logreg = linear_model.LogisticRegression(C=1000)\n",
        "logreg.fit(train_vectors, train_labels)\n",
        "prediction = logreg.predict(test_vectors)\n",
        "# accuracy = getAccuracy(train_labels, prediction)\n",
        "# print('Accuracy: ' + repr(accuracy) + '%')\n",
        "\n",
        "print(logreg.score(test_vectors,test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nCN_15JlxrII",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#tuning log reg\n",
        "from sklearn import linear_model, datasets\n",
        "logreg = linear_model.LogisticRegression(C=1000)\n",
        "logreg.fit(train_vectors, train_labels)\n",
        "prediction = logreg.predict(test_vectors)\n",
        "# accuracy = getAccuracy(train_labels, prediction)\n",
        "# print('Accuracy: ' + repr(accuracy) + '%')\n",
        "\n",
        "print(logreg.score(test_vectors,test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7QdoMDu0HgO5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "from sklearn import linear_model, datasets\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n",
        "\n",
        "clf = linear_model.LogisticRegression()\n",
        "\n",
        "param_grid = {\n",
        "  'C' :[0.1,100,1000,10000]\n",
        "\n",
        "}\n",
        "scorers = {\n",
        "    'accuracy_score': make_scorer(accuracy_score)\n",
        "}\n",
        "\n",
        "\n",
        "grid_search_clf = grid_search_wrapper(refit_score='accuracy_score')\n",
        "grid_search_clf.fit(train_vectors, train_labels)\n",
        "print(grid_search_clf.score(test_vectors,test_labels))\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hnmwx--0Iq46",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "2TjzAgKLo5jE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "### Naive-bayes\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clfs = MultinomialNB()\n",
        "clfs.fit(train_vectors, train_labels)\n",
        "print(clfs.score(test_vectors,test_labels))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3W81MuGMH3cv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "##Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n",
        "\n",
        "clf = RandomForestClassifier(n_jobs=-1)\n",
        "\n",
        "param_grid = {\n",
        "   # 'min_samples_split': [1000,10000], \n",
        "    #'n_estimators' : [100,300],\n",
        "    'n_estimators' : [300,500],\n",
        "    #'max_depth': [10,30],\n",
        "   # 'max_features': [10,20]\n",
        "}\n",
        "scorers = {\n",
        "    'precision_score': make_scorer(precision_score),\n",
        "    'recall_score': make_scorer(recall_score),\n",
        "    'accuracy_score': make_scorer(accuracy_score)\n",
        "}\n",
        "\n",
        "grid_search_clf = grid_search_wrapper(refit_score='accuracy_score')\n",
        "grid_search_clf.fit(train_vectors, train_labels)\n",
        "print(grid_search_clf.score(test_vectors,test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xDc0pM4yKdo-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "##Adaboost\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "clf = AdaBoostClassifier(n_estimators=50,\n",
        "                         learning_rate=1,\n",
        "                         random_state=0)\n",
        "model = clf.fit(train_vectors, train_labels)\n",
        "prediction = clf.predict(test_vectors)\n",
        "print(clf.score(test_vectors,test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QWlgWEqppb2v",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "##Adaboost tuned\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n",
        "\n",
        "clf = AdaBoostClassifier()\n",
        "\n",
        "param_grid = {\n",
        " \n",
        "    #'n_estimators' : [50,100,300,400],\n",
        "    'n_estimators' : [50,400],\n",
        "    #'learning_rate': [0.01,0.1,0.5,1],\n",
        "    'learning_rate': [0.5,1],\n",
        " \n",
        "}\n",
        "scorers = {\n",
        "\n",
        "    'accuracy_score': make_scorer(accuracy_score)\n",
        "}\n",
        "\n",
        "grid_search_clf = grid_search_wrapper(refit_score='accuracy_score')\n",
        "grid_search_clf.fit(train_vectors, train_labels)\n",
        "print(grid_search_clf.score(test_vectors,test_labels))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xmdAXZxtnToC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "###Decision trees\n",
        "from sklearn import tree\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(train_vectors, train_labels)\n",
        "print(clf.score(test_vectors,test_labels))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XiQyz8RYi0c3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "##Svm non linear\n",
        "from sklearn import svm\n",
        "print(\"rbf\")\n",
        "model = svm.SVC(kernel='rbf') \n",
        "model.fit(train_vectors, train_labels) \n",
        "prediction = model.predict(test_vectors)\n",
        "print(model.score(test_vectors,test_labels))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6bpwBSmfu4zB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "## Svm tunning\n",
        "from sklearn import svm\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n",
        "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
        "gammas = [0.001, 0.01, 0.1, 1]\n",
        "param_grid = {'C': Cs, 'gamma' : gammas}\n",
        "scorers = {\n",
        "\n",
        "    'accuracy_score': make_scorer(accuracy_score)\n",
        "}\n",
        "clf = svm.SVC(kernel='rbf') \n",
        "grid_search_clf = grid_search_wrapper(refit_score='accuracy_score')\n",
        "grid_search_clf.fit(train_vectors, train_labels)\n",
        "print(grid_search_clf.score(test_vectors,test_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1vEnP6cVpscb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(train_vectors, train_labels)\n",
        "prediction = knn.predict(test_vectors)\n",
        "accuracy = getAccuracy(train_labels, prediction)\n",
        "print('Accuracy: ' + repr(accuracy) + '%')\n",
        "print(clf.score(test_vectors,test_labels))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bhFPmzL6B_42",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Important notes:\n",
        "when lemmatized on tf idf accuracy decreased by 2% in some\n",
        "*tf idf rand forests max fepth =2 0.67\n",
        "\n",
        "\n",
        "tf idf : log reg :87.5%, adaboost 80% and des trees 70% with lemmatization\n",
        "\n",
        "without lemma and tuning :rand : 54% (100,300 estimators and 10 and 30 other )and adaboost 79.852%\n",
        "\n",
        "with tuning: random forests : 85.5%\n",
        "\n",
        "\n",
        "without preprocessing at all expept html removal: NB 85.4% ,log reg 88.6% best c is 1000,adaboost 80.2%,without tunning any\n",
        "with tuning : 83.6% rand forests\n",
        "\n",
        "with stop words removal and html only log reg 88.3%\n",
        "without any prep : log reg 88.5%\n",
        "\n",
        "\n",
        "without preprocessing but with n grams 1-3 : log reg :88.5%\n",
        "\n",
        "with html and lemmatization only: 88.624%\n",
        "\n",
        "with html ,stopwords and lemmatization : 88.3%\n",
        "\n"
      ]
    }
  ]
}