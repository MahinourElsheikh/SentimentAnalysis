{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment#2-SentimentAnalysis.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ZRhvaZZlS1VE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Dataset credits and copyrights:**\n",
        "\n",
        "InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
        "  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
        "  \n",
        "  title     = {Learning Word Vectors for Sentiment Analysis},\n",
        "  \n",
        "  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
        "  \n",
        "  month     = {June},\n",
        "  \n",
        "  year      = {2011},\n",
        "  \n",
        "  address   = {Portland, Oregon, USA},\n",
        "  \n",
        "  publisher = {Association for Computational Linguistics},\n",
        "  \n",
        "  pages     = {142--150},\n",
        "  \n",
        "  url       = {http://www.aclweb.org/anthology/P11-1015}\n",
        "}\n",
        "\n",
        "\n",
        "References\n",
        "\n",
        "Potts, Christopher. 2011. On the negativity of negation. In Nan Li and\n",
        "David Lutz, eds., Proceedings of Semantics and Linguistic Theory 20,\n",
        "636-659.\n"
      ]
    },
    {
      "metadata": {
        "id": "zmAm1ddciU2q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.a.1. Downloading dataset,extracting compressed files and moving into the folder containg data"
      ]
    },
    {
      "metadata": {
        "id": "CRRDBMtKiVQa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!rm -rf datalab\n",
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!ls\n",
        "!uncompress aclImdb_v1.tar.gz\n",
        "!tar -xvf aclImdb_v1.tar\n",
        "!rm aclImdb_v1.tar\n",
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zzKG8S_ZB2b2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls aclImdb\n",
        "!ls aclImdb/train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rhUtqFlm5WZ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### **Reading files containing reviews**"
      ]
    },
    {
      "metadata": {
        "id": "ZKBSMyaZ0Ih8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "'''\n",
        "function to read all text file names in a given folder\n",
        "@param  path: given in this form '/path/'\n",
        "'''\n",
        "def txt_file_names_list(path):\n",
        "    txt_files=glob.glob('.'+path+'*.txt')\n",
        "    return txt_files\n",
        "  \n",
        "#testing that function actually works\n",
        "text_files=txt_file_names_list('/aclImdb/train/pos/')\n",
        "print(len(text_files))\n",
        "print(text_files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UBsU7_Mq3TbY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#made lists of names of files containing reviews\n",
        "#tested\n",
        "pos_train_txt_names = txt_file_names_list('/aclImdb/train/pos/')\n",
        "neg_train_txt_names = txt_file_names_list('/aclImdb/train/neg/')\n",
        "pos_test_txt_names = txt_file_names_list('/aclImdb/test/pos/')\n",
        "neg_test_txt_names = txt_file_names_list('/aclImdb/test/neg/')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jrosLxnP53sC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Function\n",
        "Given an array of strings of paths(names) of files to be read \n",
        "reads each file and saves all text in a string list\n",
        "\n",
        "@param text_file_names     list of text file names and paths to them\n",
        "@return text_files         list of contents of given text files\n",
        "'''\n",
        "#tested and it works\n",
        "def capture_text_from_files(text_file_paths,number_of_files):\n",
        "  text_files=[]\n",
        "  for fileNo in range(len(text_file_paths)):\n",
        "      f = open(text_file_paths[fileNo], 'r')\n",
        "      lines = f.readlines()\n",
        "      text=\"\"\n",
        "      f.close()\n",
        "      for lineNo in range(len(lines)):\n",
        "        text+=\" \"+lines[lineNo]\n",
        "      text_files.append(text)\n",
        "  return text_files\n",
        "  \n",
        "#testing \n",
        "pos_reviews_train=capture_text_from_files(pos_train_txt_names,len(pos_train_txt_names) )\n",
        "print(len(pos_reviews_train))\n",
        "print(pos_train_txt_names[0])\n",
        "print(pos_reviews_train[0])\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "llQC_RRtkY5w",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#getting reviews text into lists to preprocess :\n",
        "pos_reviews_train_list=capture_text_from_files(pos_train_txt_names,len(pos_train_txt_names) )\n",
        "neg_reviews_train_list=capture_text_from_files(neg_train_txt_names,len(neg_train_txt_names) )\n",
        "pos_reviews_test_list=capture_text_from_files(pos_test_txt_names,len(pos_test_txt_names) )\n",
        "neg_reviews_test_list=capture_text_from_files(neg_test_txt_names,len(pos_train_txt_names) )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hlOY9_015jgq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Text Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "JFaXMKB9EYxk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "removing html tags"
      ]
    },
    {
      "metadata": {
        "id": "vAYugurP5iU-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89ff5d3f-33e7-4f09-dca1-2a8196151799",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522264001304,
          "user_tz": -120,
          "elapsed": 688,
          "user": {
            "displayName": "Kareem Abdel Salam",
            "photoUrl": "//lh5.googleusercontent.com/-FFkZs03hTYw/AAAAAAAAAAI/AAAAAAAAJYE/suktak0dYDI/s50-c-k-no/photo.jpg",
            "userId": "111052780768832987513"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#playground : testing how to remove html tags from text\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup \n",
        "x=\"</br> This <br>is <Kareem>the <a>wanted clean</a> text \"\n",
        "x = BeautifulSoup(x,\"html5lib\").get_text()\n",
        "print(x)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " This is the wanted clean text \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8iq6RopT8Ope",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#removing html tags from reviews not to confuse classifiers\n",
        "\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "'''\n",
        "Function to clear all html tags from all text in a list of strings\n",
        "\n",
        "@param text_list : list of strings targeted to clean\n",
        "'''\n",
        "def clean_html_from_list(text_list):\n",
        "\n",
        "  for i in range(len(text_list)):\n",
        "    text_list[i]=BeautifulSoup(text_list[i],\"html5lib\").get_text()\n",
        "    \n",
        "  return text_list\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nFwyPxJP9jtM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da39c2a2-2121-43b2-9389-ec901dad73e8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522265018592,
          "user_tz": -120,
          "elapsed": 692,
          "user": {
            "displayName": "Kareem Abdel Salam",
            "photoUrl": "//lh5.googleusercontent.com/-FFkZs03hTYw/AAAAAAAAAAI/AAAAAAAAJYE/suktak0dYDI/s50-c-k-no/photo.jpg",
            "userId": "111052780768832987513"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#testing the function\n",
        "#acceptable accuracy for the given dataset \n",
        "text_list=[\"</br> This <br>is <Kareem>the <a>wanted clean</a> text \",\"kareem\",\"<bla\",\"bla>\",\"word/>\",\"</word\",\"<talk/\"]\n",
        "clean_html_from_list(text_list)\n",
        "print(text_list)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' This is the wanted clean text ', 'kareem', '', 'bla>', 'word/>', '', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "enhesunHDn5I",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#using the function on data\n",
        "clean_html_from_list(pos_reviews_train_list)\n",
        "clean_html_from_list(neg_reviews_train_list)\n",
        "clean_html_from_list(pos_reviews_test_list)\n",
        "clean_html_from_list(neg_reviews_test_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sYa3CN13EcZY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "spell checker : (still no good ones in libraries and will use a naive one or implement our own but not necessary now)\n",
        "so I didn't do it to dataset until consulting others"
      ]
    },
    {
      "metadata": {
        "id": "yzvfpZ7oEhM6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 3
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "3f2db328-399c-4c1b-e2e9-24897e3953df",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522266725716,
          "user_tz": -120,
          "elapsed": 6472,
          "user": {
            "displayName": "Kareem Abdel Salam",
            "photoUrl": "//lh5.googleusercontent.com/-FFkZs03hTYw/AAAAAAAAAAI/AAAAAAAAJYE/suktak0dYDI/s50-c-k-no/photo.jpg",
            "userId": "111052780768832987513"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#TODO\n",
        "!pip install -U textblob\n",
        "!pip install -U autocorrect\n",
        "from textblob import TextBlob\n",
        "from autocorrect import spell\n"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: textblob in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already up-to-date: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob)\n",
            "Requirement already up-to-date: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob)\n",
            "Requirement already up-to-date: autocorrect in /usr/local/lib/python3.6/dist-packages\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BmsvbZkOIWGe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 3
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "3f807c1e-9b3c-4c53-bf41-26f45da4ad92",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522267117710,
          "user_tz": -120,
          "elapsed": 6960,
          "user": {
            "displayName": "Kareem Abdel Salam",
            "photoUrl": "//lh5.googleusercontent.com/-FFkZs03hTYw/AAAAAAAAAAI/AAAAAAAAJYE/suktak0dYDI/s50-c-k-no/photo.jpg",
            "userId": "111052780768832987513"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "blob = TextBlob('tihs assignmt si on itss tim excpt fr midtrms')\n",
        "print(\"blob's:\")\n",
        "print(blob.correct())\n",
        "\n",
        "x='tihs assignmt si on itss tim excpt fr midtrms'\n",
        "print(\"autocorrect:\")\n",
        "print(spell(x))\n",
        "\n",
        "#blob better and faster"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "blob's:\n",
            "this assignat si on its tim except fr midtrms\n",
            "autocorrect:\n",
            "tihs assignmt si on itss tim excpt fr midtrms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fMCqWhPWMWsM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "stop words removal (is,are,the,this ....etc) :"
      ]
    },
    {
      "metadata": {
        "id": "ha9-sfEuMfiW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}